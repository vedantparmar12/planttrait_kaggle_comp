{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8GIYvfsLKzn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipt = '/kaggle/input/planttraits2024'\n",
        "opt = '/kaggle/working/'\n",
        "netpth = '/kaggle/input/planttrails2024efficient/model.pth'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0, 1\""
      ],
      "metadata": {
        "id": "o8MGp_mwLO-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModalNetwork(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(MultiModalNetwork, self).__init__()\n",
        "\n",
        "        self.efficientnet_backbone = models.efficientnet_b0(pretrained=True)\n",
        "        self.efficientnet_backbone = nn.Sequential(*list(self.efficientnet_backbone.children())[:-1])  # 最後の分類層を除外\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "\n",
        "        self.dense1 = nn.Linear(155, 326)\n",
        "        self.dense2 = nn.Linear(326, 64)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.concat_dense = nn.Linear(1280 + 64, num_classes)\n",
        "\n",
        "    def forward(self, image_input, numerical_input):\n",
        "        if self.train:\n",
        "            x1 = self.efficientnet_backbone(image_input)\n",
        "            x1 = self.pooling(x1).view(-1, x1.shape[1])\n",
        "            x1 = self.dropout1(x1)\n",
        "\n",
        "            x2 = nn.functional.relu(self.dense1(numerical_input))\n",
        "            x2 = nn.functional.relu(self.dense2(x2))\n",
        "            x2 = self.dropout2(x2)\n",
        "\n",
        "\n",
        "            x3 = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "\n",
        "            x3 = self.concat_dense(x3)\n",
        "            return x3\n",
        "\n",
        "        elif self.eval:\n",
        "\n",
        "            x1 = self.efficientnet_backbone(image_input)\n",
        "            x1 = self.pooling(x1).view(-1, x1.shape[1])\n",
        "\n",
        "            x2 = nn.functional.relu(self.dense1(numerical_input))\n",
        "            x2 = nn.functional.relu(self.dense2(x2))\n",
        "\n",
        "            x3 = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "            x3 = self.concat_dense(x)\n",
        "\n",
        "            return x3\n",
        "\n",
        "\n",
        "class PlantTraitsDataset(Dataset):\n",
        "    def __init__(self, csv_file, train=True, transform=None):\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        self.ids = df['id']\n",
        "\n",
        "        self.features = df.iloc[:, 1:156]\n",
        "        self.features = (self.features - self.features.mean(axis=0)) / self.features.std(axis=0)\n",
        "\n",
        "        self.labels = df.iloc[:, 158:164]\n",
        "        self.std = self.labels.std(axis=0)\n",
        "        self.mean = self.labels.mean(axis=0)\n",
        "        self.labels = (self.labels - self.mean) / self.std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if self.train:\n",
        "            image_path = os.path.join(ipt, 'train_images', str(self.ids.iloc[idx]) + '.jpeg')\n",
        "        else:\n",
        "            image_path = os.path.join(ipt, 'test_images', str(self.ids.iloc[idx]) + '.jpeg')\n",
        "        image = Image.open(image_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        features = torch.tensor(self.features.iloc[idx].values.astype('float32'))\n",
        "        if self.train:\n",
        "            labels = torch.tensor(self.labels.iloc[idx].values.astype('float32'))\n",
        "            return image, features, labels\n",
        "        else:\n",
        "            return image, features"
      ],
      "metadata": {
        "id": "3Hjn1WGhLPx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4482, 0.4525, 0.3360], std=[0.1086, 0.0971, 0.1172]),\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4482, 0.4525, 0.3360], std=[0.1086, 0.0971, 0.1172]),\n",
        "])\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "AP_zAelfLhWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "model = MultiModalNetwork(num_classes=6)\n",
        "model = model.to(device)\n",
        "model = torch.nn.DataParallel(model)\n",
        "\n",
        "model.load_state_dict(torch.load(netpth))"
      ],
      "metadata": {
        "id": "LAaD-goGLkN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "dataset = PlantTraitsDataset(os.path.join(ipt, 'train.csv'), transform=train_transform, train=True)\n",
        "testset = PlantTraitsDataset(os.path.join(ipt, 'test.csv'), transform=test_transform, train=False)\n",
        "test_loader = DataLoader(testset, batch_size=256, shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    with tqdm(total=len(test_loader)) as pbar:\n",
        "        for i, (image, numerical) in enumerate(test_loader):\n",
        "            image = image.to(device)\n",
        "            numerical = numerical.to(device)\n",
        "            output = model(image, numerical)\n",
        "            pbar.update(1)\n",
        "            predictions.append(output.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "cEr-RNPSLnCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = [0.3993, 18, 0.5, 1.7, 30, 1500]\n",
        "stds = [0.3, 10, 1, 1, 50, 1500]\n",
        "\n",
        "print(f'mean:{means} stds:{stds}')\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "predictions = (predictions * stds ) + means"
      ],
      "metadata": {
        "id": "fx2R7ujpLpTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ids = pd.read_csv(os.path.join(ipt, 'test.csv'))['id']\n",
        "\n",
        "\n",
        "submission_df = pd.DataFrame(predictions, columns=['X4', 'X11', 'X18', 'X50', 'X26', 'X3112'])\n",
        "submission_df.insert(0, 'id', ids)\n",
        "\n",
        "\n",
        "submission_path = 'submission.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "submission_df"
      ],
      "metadata": {
        "id": "W0GR4LLmLris"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n",
        "train =pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n",
        "\n",
        "train = train[train['X4_mean'] >= 0]\n",
        "y_columns = [col for col in train.columns if col.endswith('_mean')]\n",
        "target = train[y_columns]\n",
        "\n",
        "target = target[['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']]"
      ],
      "metadata": {
        "id": "0qf-Ji3OLtzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_train = target[target['X4_mean'] >= 0]\n",
        "filtered_train = filtered_train[filtered_train['X11_mean'] < 100]\n",
        "filtered_train= filtered_train[filtered_train['X18_mean'] < 50]\n",
        "filtered_train= filtered_train[filtered_train['X26_mean'] < 5000]\n",
        "filtered_train= filtered_train[filtered_train['X50_mean'] < 10]\n",
        "filtered_train[filtered_train['X3112_mean'] < 25000]\n",
        "\n",
        "mean_values = filtered_train.mean()\n",
        "prediction_columns = ['X4', 'X11', 'X18', 'X50', 'X26', 'X3112']\n",
        "\n",
        "submission = pd.DataFrame({'id': test['id']})\n",
        "submission[prediction_columns] = mean_values\n",
        "submission"
      ],
      "metadata": {
        "id": "mKg3uJTyLwHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = submission[prediction_columns] + submission_df[prediction_columns]\n",
        "submission_df.insert(0, 'id', ids)\n",
        "\n",
        "submission_df"
      ],
      "metadata": {
        "id": "VREBFXiGLyL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv(submission_path, index=False)"
      ],
      "metadata": {
        "id": "hVKbkXbSL0Oy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}